# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: gptchat_v2.proto
# Protobuf Python Version: 4.25.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()

DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x10gptchat_v2.proto\x12\x12giga.controller.v2\"}\n\x0b\x43hatRequest\x12\x30\n\x07options\x18\x01 \x01(\x0b\x32\x1f.giga.controller.v2.ChatOptions\x12\r\n\x05model\x18\x02 \x01(\t\x12-\n\x08messages\x18\x03 \x03(\x0b\x32\x1b.giga.controller.v2.Message\"\xc0\x01\n\x0b\x43hatOptions\x12\x18\n\x0btemperature\x18\x01 \x01(\x02H\x00\x88\x01\x01\x12\x12\n\x05top_p\x18\x02 \x01(\x02H\x01\x88\x01\x01\x12\t\n\x01n\x18\x03 \x01(\x05\x12\x12\n\nmax_tokens\x18\x04 \x01(\x03\x12\x1a\n\x12repetition_penalty\x18\x05 \x01(\x02\x12\x1b\n\x0eoptional_flags\x18\x06 \x01(\x0cH\x02\x88\x01\x01\x42\x0e\n\x0c_temperatureB\x08\n\x06_top_pB\x11\n\x0f_optional_flags\"(\n\x07Message\x12\x0c\n\x04role\x18\x01 \x01(\t\x12\x0f\n\x07\x63ontent\x18\x02 \x01(\t\"\x87\x01\n\x0c\x43hatResponse\x12+\n\x07\x63hoices\x18\x01 \x03(\x0b\x32\x1a.giga.controller.v2.Choice\x12(\n\x05usage\x18\x02 \x01(\x0b\x32\x19.giga.controller.v2.Usage\x12\r\n\x05model\x18\x03 \x01(\t\x12\x11\n\ttimestamp\x18\x04 \x01(\x03\"\\\n\x06\x43hoice\x12,\n\x07message\x18\x01 \x01(\x0b\x32\x1b.giga.controller.v2.Message\x12\x15\n\rfinish_reason\x18\x02 \x01(\t\x12\r\n\x05index\x18\x03 \x01(\x05\"\x80\x01\n\x05Usage\x12\x15\n\rprompt_tokens\x18\x01 \x01(\x05\x12\x1e\n\x11\x63ompletion_tokens\x18\x02 \x01(\x05H\x00\x88\x01\x01\x12\x19\n\x0ctotal_tokens\x18\x03 \x01(\x05H\x01\x88\x01\x01\x42\x14\n\x12_completion_tokensB\x0f\n\r_total_tokens\"@\n\x11\x45mbeddingsRequest\x12\x12\n\x05model\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\r\n\x05input\x18\x02 \x03(\tB\x08\n\x06_model\"e\n\x12\x45mbeddingsResponse\x12\x31\n\nembeddings\x18\x01 \x03(\x0b\x32\x1d.giga.controller.v2.Embedding\x12\x12\n\x05model\x18\x02 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_model\"g\n\tEmbedding\x12\x0e\n\x06object\x18\x01 \x01(\t\x12\x11\n\tembedding\x18\x02 \x03(\x02\x12\r\n\x05index\x18\x03 \x01(\x05\x12(\n\x05usage\x18\x04 \x01(\x0b\x32\x19.giga.controller.v2.Usage\"\x13\n\x11ListModelsRequest\"?\n\x12ListModelsResponse\x12)\n\x06models\x18\x01 \x03(\x0b\x32\x19.giga.controller.v2.Model\"6\n\x05Model\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06object\x18\x02 \x01(\t\x12\x0f\n\x07ownedBy\x18\x03 \x01(\t\"$\n\x14RetrieveModelRequest\x12\x0c\n\x04name\x18\x01 \x01(\t\"A\n\x15RetrieveModelResponse\x12(\n\x05model\x18\x01 \x01(\x0b\x32\x19.giga.controller.v2.Model2X\n\x0b\x43hatService\x12I\n\x04\x43hat\x12\x1f.giga.controller.v2.ChatRequest\x1a .giga.controller.v2.ChatResponse2p\n\x11\x45mbeddingsService\x12[\n\nEmbeddings\x12%.giga.controller.v2.EmbeddingsRequest\x1a&.giga.controller.v2.EmbeddingsResponse2\xd2\x01\n\rModelsService\x12[\n\nListModels\x12%.giga.controller.v2.ListModelsRequest\x1a&.giga.controller.v2.ListModelsResponse\x12\x64\n\rRetrieveModel\x12(.giga.controller.v2.RetrieveModelRequest\x1a).giga.controller.v2.RetrieveModelResponseB\rZ\x0b./;protocolb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'gptchat_v2_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
    _globals['DESCRIPTOR']._options = None
    _globals['DESCRIPTOR']._serialized_options = b'Z\013./;protocol'
    _globals['_CHATREQUEST']._serialized_start = 40
    _globals['_CHATREQUEST']._serialized_end = 165
    _globals['_CHATOPTIONS']._serialized_start = 168
    _globals['_CHATOPTIONS']._serialized_end = 360
    _globals['_MESSAGE']._serialized_start = 362
    _globals['_MESSAGE']._serialized_end = 402
    _globals['_CHATRESPONSE']._serialized_start = 405
    _globals['_CHATRESPONSE']._serialized_end = 540
    _globals['_CHOICE']._serialized_start = 542
    _globals['_CHOICE']._serialized_end = 634
    _globals['_USAGE']._serialized_start = 637
    _globals['_USAGE']._serialized_end = 765
    _globals['_EMBEDDINGSREQUEST']._serialized_start = 767
    _globals['_EMBEDDINGSREQUEST']._serialized_end = 831
    _globals['_EMBEDDINGSRESPONSE']._serialized_start = 833
    _globals['_EMBEDDINGSRESPONSE']._serialized_end = 934
    _globals['_EMBEDDING']._serialized_start = 936
    _globals['_EMBEDDING']._serialized_end = 1039
    _globals['_LISTMODELSREQUEST']._serialized_start = 1041
    _globals['_LISTMODELSREQUEST']._serialized_end = 1060
    _globals['_LISTMODELSRESPONSE']._serialized_start = 1062
    _globals['_LISTMODELSRESPONSE']._serialized_end = 1125
    _globals['_MODEL']._serialized_start = 1127
    _globals['_MODEL']._serialized_end = 1181
    _globals['_RETRIEVEMODELREQUEST']._serialized_start = 1183
    _globals['_RETRIEVEMODELREQUEST']._serialized_end = 1219
    _globals['_RETRIEVEMODELRESPONSE']._serialized_start = 1221
    _globals['_RETRIEVEMODELRESPONSE']._serialized_end = 1286
    _globals['_CHATSERVICE']._serialized_start = 1288
    _globals['_CHATSERVICE']._serialized_end = 1376
    _globals['_EMBEDDINGSSERVICE']._serialized_start = 1378
    _globals['_EMBEDDINGSSERVICE']._serialized_end = 1490
    _globals['_MODELSSERVICE']._serialized_start = 1493
    _globals['_MODELSSERVICE']._serialized_end = 1703
# @@protoc_insertion_point(module_scope)
